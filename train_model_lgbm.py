# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1waTaVBAE-fh6CVww9ZmEqICuyrsuwto4
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import re

#!pip install transformers torch
import torch
from transformers import BertTokenizer, BertModel

#!pip install lightgbm
from lightgbm import LGBMRegressor

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import FunctionTransformer
from sklearn.ensemble import HistGradientBoostingRegressor

#from google.colab import files
#files.upload()

df = pd.read_csv('Violence Against Women  Girls Data-1.csv')

print("Initial DataFrame Info:")
df.info()

df.head(5)

"""# DATA PRE-PROCESSING"""

# Handle missing values
df.dropna(subset=['Value'], inplace=True)

# Convert 'Survey Year' to datetime and then to year
df['Survey Year'] = pd.to_datetime(df['Survey Year']).dt.year

# Simple text preprocessing for 'Question' column
df['Processed_Question'] = df['Question'].apply(lambda x: x.lower())

"""# EXPLORATORY DATA ANALYSIS (EDA)"""

# Descriptive statistics for numerical columns
print(df[['Value', 'Survey Year']].describe())

# Value counts for key categorical columns
print("\n2. Value Counts for Key Categorical Columns:")
print("\nGender Value Counts:")
print(df['Gender'].value_counts())

print("\nDemographics Question Value Counts:")
print(df['Demographics Question'].value_counts())

print("\nDemographics Response Value Counts (Top 10):")
print(df['Demographics Response'].value_counts().head(10))

print("\nCountry Value Counts (Top 10):")
print(df['Country'].value_counts().head(10))

df['Question'].unique()

print("\nQuestion Value Counts (Top 5):")
print(df['Question'].value_counts().head(5))

# Distribution plot for 'Value' (Target Variable)
plt.figure(figsize=(10, 6))
sns.histplot(df['Value'], kde=True, bins=30)
plt.title('Distribution of Value (% of people who agree with justification)')
plt.xlabel('Value (%)')
plt.ylabel('Frequency')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('value_distribution.png')
plt.show()
print("\nSaved 'value_distribution.png'")

# 4. Bar plots for categorical features vs. 'Value' (average)
# Average Value by Gender
plt.figure(figsize=(8, 5))
sns.barplot(x='Gender', y='Value', data=df, estimator=np.mean, ci=None)
plt.title('Average Value by Gender')
plt.xlabel('Gender')
plt.ylabel('Average Value (%)')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('avg_value_by_gender.png')
plt.show()
print("Saved 'avg_value_by_gender.png'")

# Average Value by Demographics Question
plt.figure(figsize=(12, 7))
sns.barplot(x='Value', y='Demographics Question', data=df, estimator=np.mean, ci=None,
            order=df.groupby('Demographics Question')['Value'].mean().sort_values(ascending=False).index)
plt.title('Average Value by Demographics Question')
plt.xlabel('Average Value (%)')
plt.ylabel('Demographics Question')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('avg_value_by_demog_question.png')
plt.show()
print("Saved 'avg_value_by_demog_question.png'")

# Average Value by Top 10 Countries
top_10_countries = df['Country'].value_counts().head(10).index
df_top_countries = df[df['Country'].isin(top_10_countries)]
plt.figure(figsize=(14, 7))
sns.barplot(x='Value', y='Country', data=df_top_countries, estimator=np.mean, ci=None,
            order=df_top_countries.groupby('Country')['Value'].mean().sort_values(ascending=False).index)
plt.title('Average Value by Top 10 Countries')
plt.xlabel('Average Value (%)')
plt.ylabel('Country')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('avg_value_by_top_countries.png')
plt.show()
print("Saved 'avg_value_by_top_countries.png'")

"""# DEFINE FEATURES (X) AND TARGET (Y)"""

X = df[['Country', 'Gender', 'Demographics Question', 'Demographics Response', 'Processed_Question', 'Survey Year']]
y = df['Value']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create preprocessor for categorical and text features
categorical_features = ['Country', 'Gender', 'Demographics Question', 'Demographics Response']
text_features = 'Processed_Question'
numerical_features = ['Survey Year']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('text', TfidfVectorizer(max_features=5000), text_features),
        ('num', 'passthrough', numerical_features)
    ],
    remainder='passthrough'
)

"""# MODEL TRAINING WITH HISTGRADIENTBOOSTINGREGRESSOR"""

print("\nTraining the model with HistGradientBoostingRegressor...")
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('to_dense', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)), # Convert sparse output to dense
    ('regressor', HistGradientBoostingRegressor(random_state=42))
])

# Train the model
model.fit(X_train, y_train)
print("Model training complete.")

"""# MODEL EVALUATION"""

print("\nEvaluating the model...")
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

"""# MODEL BERT"""

# Convert 'Survey Year' to integer year
df['Survey Year'] = pd.to_datetime(df['Survey Year']).dt.year

BERT_EMBEDDING_DIM = 768

def get_bert_embedding_simulated(text, dim=BERT_EMBEDDING_DIM):
    """
    Fungsi placeholder untuk mensimulasikan embedding BERT.
    Dalam implementasinya akan melibatkan:
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    model = BertModel.from_pretrained('bert-base-uncased')
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    # Ambil embedding [CLS] token atau rata-rata embedding token
    # return outputs.last_hidden_state[:, 0, :].squeeze().numpy() # [CLS] token embedding
    # return torch.mean(outputs.last_hidden_state, dim=1).squeeze().numpy() # Mean pooling
    """
    # Mengembalikan vektor acak sebagai simulasi embedding BERT
    return np.random.rand(dim)

print(f"\nMenghasilkan simulasi embedding BERT untuk kolom 'Question' dengan dimensi {BERT_EMBEDDING_DIM}...")
df['bert_embeddings'] = df['Question'].apply(get_bert_embedding_simulated)
print("Simulasi embedding BERT selesai.")

# Split the BERT embedding column into separate columns
bert_embedding_df = pd.DataFrame(df['bert_embeddings'].tolist(), index=df.index)
bert_embedding_df.columns = [f'bert_embed_{i}' for i in range(BERT_EMBEDDING_DIM)]

# Combining BERT embedding with the main DataFrame
df = pd.concat([df, bert_embedding_df], axis=1)

# Now, the X feature will include the BERT embedding columns
X_columns = ['Country', 'Gender', 'Demographics Question', 'Demographics Response', 'Survey Year'] + list(bert_embedding_df.columns)
X = df[X_columns]
y = df['Value']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# CREATE PREOROCESSOR FOR CATEGORICAL AND NUMERICAL FEATURES"""

# Only demographic features need to be encoded
categorical_features = ['Country', 'Gender', 'Demographics Question', 'Demographics Response']
numerical_features = ['Survey Year'] + list(bert_embedding_df.columns) # BERT embeddings and Survey Year are numerical

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', 'passthrough', numerical_features) # Pass through numerical features (including BERT embeddings)
    ],
    remainder='passthrough' # In case there are other columns not specified
)

"""# MODEL TRAINING WITH LIGHTGBM REGRESSOR"""

print("\nMelatih model dengan LightGBM Regressor...")
# Buat pipeline dengan LightGBM Regressor
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LGBMRegressor(random_state=42, n_estimators=100, learning_rate=0.1, max_depth=7)) # Menggunakan LGBMRegressor
])

model.fit(X_train, y_train)
print("Pelatihan model selesai.")

print("\nMengevaluasi model...")
y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

model_filename = 'violence_justification_bert_lgbm_model.joblib'
joblib.dump(model, model_filename)
print(f"\nModel disimpan sebagai {model_filename}")

print("\nMenunjukkan contoh prediksi:")
sample_input = pd.DataFrame([{
    'Country': 'Afghanistan',
    'Gender': 'F',
    'Demographics Question': 'Marital status',
    'Demographics Response': 'Married or living together',
    'Question': '... if she burns the food',
    'Survey Year': 2015
}])

sample_input['bert_embeddings'] = sample_input['Question'].apply(get_bert_embedding_simulated)

bert_embedding_sample_df = pd.DataFrame(sample_input['bert_embeddings'].tolist())
bert_embedding_sample_df.columns = [f'bert_embed_{i}' for i in range(BERT_EMBEDDING_DIM)]

sample_input_processed = pd.concat([sample_input.drop(columns=['bert_embeddings']), bert_embedding_sample_df], axis=1)

sample_input_final = sample_input_processed[X_columns]


predicted_value = model.predict(sample_input_final)
print(f"Sample input:\n{sample_input.drop(columns='bert_embeddings')}")
print(f"Persentase prediksi persetujuan: {predicted_value[0]:.2f}%")

# Contoh input out-of-sample
sample_input_oos = pd.DataFrame([{
    'Country': 'Unknown Country',
    'Gender': 'M',
    'Demographics Question': 'Education',
    'Demographics Response': 'No Education',
    'Question': '... if she argues with him',
    'Survey Year': 2010
}])

sample_input_oos['bert_embeddings'] = sample_input_oos['Question'].apply(get_bert_embedding_simulated)
bert_embedding_oos_df = pd.DataFrame(sample_input_oos['bert_embeddings'].tolist())
bert_embedding_oos_df.columns = [f'bert_embed_{i}' for i in range(BERT_EMBEDDING_DIM)]
sample_input_oos_processed = pd.concat([sample_input_oos.drop(columns=['bert_embeddings']), bert_embedding_oos_df], axis=1)
sample_input_oos_final = sample_input_oos_processed[X_columns]

predicted_value_oos = model.predict(sample_input_oos_final)
print(f"\nSample out-of-sample input:\n{sample_input_oos.drop(columns='bert_embeddings')}")
print(f"Persentase prediksi persetujuan untuk out-of-sample: {predicted_value_oos[0]:.2f}%")

model_filename = 'violence_justification_lgbm_model.joblib'
joblib.dump(model, model_filename)
print(f"\nModel disimpan sebagai {model_filename}")